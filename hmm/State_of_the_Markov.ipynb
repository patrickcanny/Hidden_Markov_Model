{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS 738: Hidden Markov Models\n",
    "#### Liam Ormiston & Patrick Canny\n",
    "### Background\n",
    "We thought it would be fun to see how a Hidden Markov Model would do at generating a State of the Union Address. This is partially due to Liam's backround in Communications and speech writing in particular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "Let's first import the code.\n",
    "\n",
    "<i>Note: we adapted our code from https://github.com/ashwinmj/word-predictionâ€‹<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmm, tools, combine_all, combine_pres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>hmm: contains most of the logic for the hidden markov model</li>\n",
    "    <li>tools: contains helper functions that support the hmm functions</li>\n",
    "    <li>combine_all: gives us combined_all.txt a file of all State of the Union Addresses</li>\n",
    "    <li>combine_pres: contains functions to create and remove combined_pres.txt, a file of a certain president's addresses. If given nothing, default is set to President Woodrow Wilson.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmm import HMM\n",
    "initial_model = HMM('combined_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: combined_all.txt\n",
      "Done Training on: combined_all.txt\n"
     ]
    }
   ],
   "source": [
    "initial_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial_model is trained using combined_all_.txt which is all the State of the Union address since 1790-2018. Our code is only looking at two words at a time and trying to predict the third word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate 5 lines and see how our model does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending on the part of the immense sphere of national as well due\n",
      "public opinion in favor of substituting a\n",
      "the government has labored to establish its\n",
      "should the war between france and belgium has been made to secure reasonableness in prices of\n",
      "sentiments through a long day we began to flow between those\n"
     ]
    }
   ],
   "source": [
    "initial_model.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this is somewhat gibberish, but it's a good place to start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at what happens if we limit our model to just a specific president. We can pick Lincoln by passing in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file created\n"
     ]
    }
   ],
   "source": [
    "combine_pres.create_txt('Lincoln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_specific = HMM('combined_pres.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: combined_pres.txt\n",
      "Done Training on: combined_pres.txt\n"
     ]
    }
   ],
   "source": [
    "president_specific.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's just do 5 lines and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the united states passed the\n",
      "this plan is presented which may reach the loyal regions of east\n",
      "state of nevada has been paid to pensioners of all the\n",
      "long a line it has\n",
      "improvement and governmental institutions over the new commercial treaty between the now living had been prodded it is some relief to know that the actual receipts for the fiscal year\n"
     ]
    }
   ],
   "source": [
    "president_specific.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still gibberish but still a clear different use of words. It depends on what it generates for you, but we have seen words that have to do with the Civil War, territories, and supplies appear more often. Which makes sense since Lincoln served througout the entirity of the Civil War."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give our model a sentence to start with and it will try to complete it. For this, it will only look at the last two words and start from there. \n",
    "Let's take a look at how this goes with our initial model trained over all address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has come to my attention that our nation tonight is also true that\n"
     ]
    }
   ],
   "source": [
    "initial_model.generate(1, 'It has come to my attention that our nation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kind of cool to see what it comes up with! \n",
    "\n",
    "If you give it words that do not appear in any of the addresses, it will throw an error. This is because you gave it words that it hasn't seen before. So it cannot predict what comes after. We've added an error catch to inform you if this happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Improvements\n",
    "#### Look at more words\n",
    "Currently our model only looks at two words and finds the third word based on the probability of it appearing after the last two words. This does a fairly good job. However, it would be more accurate if we analyzed a longer chain of words. Say, five or six. This would produce more coherent sentences but would also require storing more data. \n",
    "#### Add Grammar Rules\n",
    "We could also weight probabilities of words using grammar rules. For instance, if the most likely word to come after another violates a grammar rule, reduce the probability by a set amount per violation. This could lower the probability enough to perhaps pick the second most likely word.\n",
    "#### More Data\n",
    "Obviously, more data would nice. However, a State of the Union address only occurs once a year. We could look at all presidential speeches and add those speeches with a lower weight than the State of the Union addresses. This would at least give us more words to work with and minimize the likelihood of feeding the model words that it has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
